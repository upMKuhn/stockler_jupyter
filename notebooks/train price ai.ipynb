{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woop Woop! Let's do it!!!\n",
    "\n",
    "Ok so in the \"Stock preprocessing\" Notebook we created a csv file with variouse inidicators \n",
    "and the stock prices. We also scaled the data to be as close to 0 as possible.\n",
    "\n",
    "Now we need to load the csv files, chunk the data into training batch vs validation batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 49), started 0:01:48 ago. (Use '!kill 49' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe9d834fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=../logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorboard is available on: http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from models import train_price_ai as modeling\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_files = [\n",
    "    'symbol__TSLA_2018-08-02_2019-04-30',\n",
    "    'symbol__XBIO_2018-08-02_2019-04-30'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = { file: pd.read_csv(f'../data/{file}.csv') for file in data_set_files } \n",
    "for data in data_sets.values():\n",
    "    data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol__TSLA_2018-08-02_2019-04-30\n"
     ]
    }
   ],
   "source": [
    "symbol = list(data_sets.keys())[0]\n",
    "print(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = modeling.PriceAiTrainer(data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 23:34:37.116984 140642437965632 deprecation.py:506] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = trainer.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 23:34:37.769320 140642437965632 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1352 samples, validate on 450 samples\n",
      "Epoch 1/220\n",
      "1352/1352 - 17s - loss: 0.0204 - acc: 0.0185 - val_loss: 8.7875e-04 - val_acc: 0.0244\n",
      "Epoch 2/220\n",
      "1352/1352 - 17s - loss: 8.0621e-04 - acc: 0.0207 - val_loss: 6.5117e-04 - val_acc: 0.0267\n",
      "Epoch 3/220\n",
      "1352/1352 - 16s - loss: 5.8925e-04 - acc: 0.0237 - val_loss: 6.3212e-04 - val_acc: 0.0356\n",
      "Epoch 4/220\n",
      "1352/1352 - 16s - loss: 5.5528e-04 - acc: 0.0274 - val_loss: 6.5306e-04 - val_acc: 0.0289\n",
      "Epoch 5/220\n",
      "1352/1352 - 15s - loss: 5.0259e-04 - acc: 0.0296 - val_loss: 5.9836e-04 - val_acc: 0.0578\n",
      "Epoch 6/220\n",
      "1352/1352 - 15s - loss: 6.1547e-04 - acc: 0.0422 - val_loss: 6.0419e-04 - val_acc: 0.0333\n",
      "Epoch 7/220\n",
      "1352/1352 - 15s - loss: 5.7818e-04 - acc: 0.0318 - val_loss: 0.0013 - val_acc: 0.0333\n",
      "Epoch 8/220\n",
      "1352/1352 - 16s - loss: 5.6828e-04 - acc: 0.0288 - val_loss: 5.9615e-04 - val_acc: 0.0244\n",
      "Epoch 9/220\n",
      "1352/1352 - 16s - loss: 5.3033e-04 - acc: 0.0333 - val_loss: 5.7161e-04 - val_acc: 0.0200\n",
      "Epoch 10/220\n",
      "1352/1352 - 16s - loss: 4.7697e-04 - acc: 0.0296 - val_loss: 6.1436e-04 - val_acc: 0.0267\n",
      "Epoch 11/220\n",
      "1352/1352 - 16s - loss: 5.1325e-04 - acc: 0.0296 - val_loss: 5.9298e-04 - val_acc: 0.0644\n",
      "Epoch 12/220\n",
      "1352/1352 - 16s - loss: 9.1325e-04 - acc: 0.0259 - val_loss: 0.0015 - val_acc: 0.0089\n",
      "Epoch 13/220\n",
      "1352/1352 - 16s - loss: 5.6814e-04 - acc: 0.0244 - val_loss: 0.0019 - val_acc: 0.0400\n",
      "Epoch 14/220\n",
      "1352/1352 - 16s - loss: 8.0325e-04 - acc: 0.0259 - val_loss: 0.0013 - val_acc: 0.0156\n",
      "Epoch 15/220\n",
      "1352/1352 - 16s - loss: 5.1980e-04 - acc: 0.0222 - val_loss: 5.5369e-04 - val_acc: 0.0133\n",
      "Epoch 16/220\n",
      "1352/1352 - 16s - loss: 4.7750e-04 - acc: 0.0303 - val_loss: 5.8371e-04 - val_acc: 0.0556\n",
      "Epoch 17/220\n",
      "1352/1352 - 16s - loss: 4.6917e-04 - acc: 0.0385 - val_loss: 8.1274e-04 - val_acc: 0.0111\n",
      "Epoch 18/220\n",
      "1352/1352 - 16s - loss: 5.1739e-04 - acc: 0.0340 - val_loss: 6.1003e-04 - val_acc: 0.0156\n",
      "Epoch 19/220\n",
      "1352/1352 - 16s - loss: 5.0367e-04 - acc: 0.0281 - val_loss: 5.6300e-04 - val_acc: 0.0400\n",
      "Epoch 20/220\n",
      "1352/1352 - 16s - loss: 4.6783e-04 - acc: 0.0325 - val_loss: 6.9967e-04 - val_acc: 0.0200\n",
      "Epoch 21/220\n",
      "1352/1352 - 16s - loss: 6.2258e-04 - acc: 0.0414 - val_loss: 7.8728e-04 - val_acc: 0.0400\n",
      "Epoch 22/220\n",
      "1352/1352 - 16s - loss: 4.6131e-04 - acc: 0.0311 - val_loss: 6.9355e-04 - val_acc: 0.0511\n",
      "Epoch 23/220\n",
      "1352/1352 - 16s - loss: 4.6224e-04 - acc: 0.0303 - val_loss: 0.0010 - val_acc: 0.0511\n",
      "Epoch 24/220\n",
      "1352/1352 - 16s - loss: 5.6660e-04 - acc: 0.0333 - val_loss: 5.7162e-04 - val_acc: 0.0244\n",
      "Epoch 25/220\n",
      "1352/1352 - 16s - loss: 5.1307e-04 - acc: 0.0251 - val_loss: 6.4178e-04 - val_acc: 0.0267\n",
      "Epoch 26/220\n",
      "1352/1352 - 16s - loss: 4.8001e-04 - acc: 0.0281 - val_loss: 8.1013e-04 - val_acc: 0.0467\n",
      "Epoch 27/220\n",
      "1352/1352 - 16s - loss: 5.1842e-04 - acc: 0.0385 - val_loss: 5.6492e-04 - val_acc: 0.0556\n",
      "Epoch 28/220\n",
      "1352/1352 - 16s - loss: 5.0524e-04 - acc: 0.0318 - val_loss: 6.2368e-04 - val_acc: 0.0178\n",
      "Epoch 29/220\n",
      "1352/1352 - 16s - loss: 4.7561e-04 - acc: 0.0355 - val_loss: 5.7746e-04 - val_acc: 0.0244\n",
      "Epoch 30/220\n",
      "1352/1352 - 16s - loss: 6.1201e-04 - acc: 0.0377 - val_loss: 5.4593e-04 - val_acc: 0.0578\n",
      "Epoch 31/220\n",
      "1352/1352 - 16s - loss: 6.5343e-04 - acc: 0.0473 - val_loss: 6.1168e-04 - val_acc: 0.0444\n",
      "Epoch 32/220\n",
      "1352/1352 - 16s - loss: 4.5562e-04 - acc: 0.0288 - val_loss: 5.5618e-04 - val_acc: 0.0289\n",
      "Epoch 33/220\n",
      "1352/1352 - 16s - loss: 4.4832e-04 - acc: 0.0377 - val_loss: 0.0013 - val_acc: 0.0178\n",
      "Epoch 34/220\n",
      "1352/1352 - 16s - loss: 8.5460e-04 - acc: 0.0370 - val_loss: 5.7495e-04 - val_acc: 0.0511\n",
      "Epoch 35/220\n",
      "1352/1352 - 16s - loss: 5.0419e-04 - acc: 0.0281 - val_loss: 6.0012e-04 - val_acc: 0.0178\n",
      "Epoch 36/220\n",
      "1352/1352 - 16s - loss: 5.5220e-04 - acc: 0.0296 - val_loss: 6.7675e-04 - val_acc: 0.0378\n",
      "Epoch 37/220\n",
      "1352/1352 - 16s - loss: 4.4476e-04 - acc: 0.0318 - val_loss: 6.2352e-04 - val_acc: 0.0067\n",
      "Epoch 38/220\n",
      "1352/1352 - 16s - loss: 5.0161e-04 - acc: 0.0303 - val_loss: 6.5595e-04 - val_acc: 0.0511\n",
      "Epoch 39/220\n",
      "1352/1352 - 16s - loss: 4.6456e-04 - acc: 0.0259 - val_loss: 6.1490e-04 - val_acc: 0.0200\n",
      "Epoch 40/220\n",
      "1352/1352 - 16s - loss: 4.6714e-04 - acc: 0.0325 - val_loss: 0.0011 - val_acc: 0.0200\n",
      "Epoch 41/220\n",
      "1352/1352 - 16s - loss: 5.9386e-04 - acc: 0.0392 - val_loss: 5.8780e-04 - val_acc: 0.0400\n",
      "Epoch 42/220\n",
      "1352/1352 - 16s - loss: 4.8697e-04 - acc: 0.0407 - val_loss: 7.5783e-04 - val_acc: 0.0422\n",
      "Epoch 43/220\n",
      "1352/1352 - 16s - loss: 4.6412e-04 - acc: 0.0325 - val_loss: 5.3085e-04 - val_acc: 0.0267\n",
      "Epoch 44/220\n",
      "1352/1352 - 16s - loss: 4.9448e-04 - acc: 0.0325 - val_loss: 5.6662e-04 - val_acc: 0.0444\n",
      "Epoch 45/220\n",
      "1352/1352 - 16s - loss: 4.4383e-04 - acc: 0.0407 - val_loss: 7.0975e-04 - val_acc: 0.0200\n",
      "Epoch 46/220\n",
      "1352/1352 - 16s - loss: 4.4713e-04 - acc: 0.0392 - val_loss: 7.6761e-04 - val_acc: 0.0378\n",
      "Epoch 47/220\n",
      "1352/1352 - 16s - loss: 4.7820e-04 - acc: 0.0251 - val_loss: 0.0012 - val_acc: 0.0289\n",
      "Epoch 48/220\n",
      "1352/1352 - 16s - loss: 4.6737e-04 - acc: 0.0303 - val_loss: 8.0188e-04 - val_acc: 0.0133\n",
      "Epoch 49/220\n",
      "1352/1352 - 16s - loss: 4.7122e-04 - acc: 0.0355 - val_loss: 0.0011 - val_acc: 0.0467\n",
      "Epoch 50/220\n",
      "1352/1352 - 16s - loss: 5.9594e-04 - acc: 0.0281 - val_loss: 8.3702e-04 - val_acc: 0.0444\n",
      "Epoch 51/220\n",
      "1352/1352 - 16s - loss: 4.6422e-04 - acc: 0.0259 - val_loss: 6.9089e-04 - val_acc: 0.0267\n",
      "Epoch 52/220\n",
      "1352/1352 - 16s - loss: 7.0275e-04 - acc: 0.0311 - val_loss: 6.3654e-04 - val_acc: 0.0222\n",
      "Epoch 53/220\n",
      "1352/1352 - 16s - loss: 5.1049e-04 - acc: 0.0296 - val_loss: 9.0886e-04 - val_acc: 0.0244\n",
      "Epoch 54/220\n",
      "1352/1352 - 16s - loss: 4.4773e-04 - acc: 0.0281 - val_loss: 6.3105e-04 - val_acc: 0.0200\n",
      "Epoch 55/220\n",
      "1352/1352 - 16s - loss: 4.3095e-04 - acc: 0.0311 - val_loss: 5.9498e-04 - val_acc: 0.0378\n",
      "Epoch 56/220\n",
      "1352/1352 - 16s - loss: 4.4863e-04 - acc: 0.0251 - val_loss: 5.8038e-04 - val_acc: 0.0422\n",
      "Epoch 57/220\n",
      "1352/1352 - 16s - loss: 5.0041e-04 - acc: 0.0303 - val_loss: 0.0010 - val_acc: 0.0111\n",
      "Epoch 58/220\n",
      "1352/1352 - 16s - loss: 4.5624e-04 - acc: 0.0355 - val_loss: 5.5706e-04 - val_acc: 0.0533\n",
      "Epoch 59/220\n",
      "1352/1352 - 16s - loss: 4.4240e-04 - acc: 0.0348 - val_loss: 6.7002e-04 - val_acc: 0.0156\n",
      "Epoch 60/220\n",
      "1352/1352 - 16s - loss: 4.6034e-04 - acc: 0.0355 - val_loss: 5.6824e-04 - val_acc: 0.0200\n",
      "Epoch 61/220\n",
      "1352/1352 - 16s - loss: 4.2654e-04 - acc: 0.0259 - val_loss: 5.6158e-04 - val_acc: 0.0511\n",
      "Epoch 62/220\n",
      "1352/1352 - 16s - loss: 4.7435e-04 - acc: 0.0362 - val_loss: 6.1065e-04 - val_acc: 0.0178\n",
      "Epoch 63/220\n",
      "1352/1352 - 16s - loss: 4.3970e-04 - acc: 0.0333 - val_loss: 5.3756e-04 - val_acc: 0.0244\n",
      "Epoch 64/220\n",
      "1352/1352 - 16s - loss: 4.7751e-04 - acc: 0.0296 - val_loss: 6.5504e-04 - val_acc: 0.0356\n",
      "Epoch 65/220\n",
      "1352/1352 - 16s - loss: 4.4312e-04 - acc: 0.0348 - val_loss: 5.5138e-04 - val_acc: 0.0422\n",
      "Epoch 66/220\n",
      "1352/1352 - 16s - loss: 4.7967e-04 - acc: 0.0348 - val_loss: 5.7458e-04 - val_acc: 0.0178\n",
      "Epoch 67/220\n",
      "1352/1352 - 16s - loss: 4.7398e-04 - acc: 0.0399 - val_loss: 5.2948e-04 - val_acc: 0.0156\n",
      "Epoch 68/220\n",
      "1352/1352 - 16s - loss: 4.1810e-04 - acc: 0.0377 - val_loss: 0.0010 - val_acc: 0.0289\n",
      "Epoch 69/220\n",
      "1352/1352 - 16s - loss: 5.1284e-04 - acc: 0.0333 - val_loss: 5.3907e-04 - val_acc: 0.0222\n",
      "Epoch 70/220\n",
      "1352/1352 - 16s - loss: 4.5866e-04 - acc: 0.0407 - val_loss: 6.2392e-04 - val_acc: 0.0222\n",
      "Epoch 71/220\n",
      "1352/1352 - 16s - loss: 4.1141e-04 - acc: 0.0281 - val_loss: 5.8455e-04 - val_acc: 0.0200\n",
      "Epoch 72/220\n",
      "1352/1352 - 16s - loss: 4.3774e-04 - acc: 0.0325 - val_loss: 8.9220e-04 - val_acc: 0.0467\n",
      "Epoch 73/220\n",
      "1352/1352 - 16s - loss: 4.5909e-04 - acc: 0.0407 - val_loss: 5.4579e-04 - val_acc: 0.0267\n",
      "Epoch 74/220\n",
      "1352/1352 - 16s - loss: 4.2310e-04 - acc: 0.0370 - val_loss: 6.9192e-04 - val_acc: 0.0111\n",
      "Epoch 75/220\n",
      "1352/1352 - 16s - loss: 4.3232e-04 - acc: 0.0429 - val_loss: 5.3285e-04 - val_acc: 0.0178\n",
      "Epoch 76/220\n",
      "1352/1352 - 16s - loss: 4.8107e-04 - acc: 0.0207 - val_loss: 5.4743e-04 - val_acc: 0.0222\n",
      "Epoch 77/220\n",
      "1352/1352 - 16s - loss: 4.5022e-04 - acc: 0.0296 - val_loss: 6.7012e-04 - val_acc: 0.0356\n",
      "Epoch 78/220\n",
      "1352/1352 - 16s - loss: 4.5576e-04 - acc: 0.0370 - val_loss: 6.5263e-04 - val_acc: 0.0178\n",
      "Epoch 79/220\n",
      "1352/1352 - 16s - loss: 4.1523e-04 - acc: 0.0362 - val_loss: 6.8871e-04 - val_acc: 0.0533\n",
      "Epoch 80/220\n",
      "1352/1352 - 16s - loss: 4.2766e-04 - acc: 0.0303 - val_loss: 6.0451e-04 - val_acc: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/220\n",
      "1352/1352 - 16s - loss: 4.8848e-04 - acc: 0.0311 - val_loss: 9.5818e-04 - val_acc: 0.0400\n",
      "Epoch 82/220\n",
      "1352/1352 - 16s - loss: 6.7030e-04 - acc: 0.0281 - val_loss: 9.2030e-04 - val_acc: 0.0489\n",
      "Epoch 83/220\n",
      "1352/1352 - 16s - loss: 4.5002e-04 - acc: 0.0414 - val_loss: 5.3428e-04 - val_acc: 0.0289\n",
      "Epoch 84/220\n",
      "1352/1352 - 16s - loss: 4.5688e-04 - acc: 0.0214 - val_loss: 5.3226e-04 - val_acc: 0.0178\n",
      "Epoch 85/220\n",
      "1352/1352 - 16s - loss: 4.7241e-04 - acc: 0.0348 - val_loss: 0.0012 - val_acc: 0.0178\n",
      "Epoch 86/220\n",
      "1352/1352 - 16s - loss: 4.9709e-04 - acc: 0.0422 - val_loss: 5.4769e-04 - val_acc: 0.0400\n",
      "Epoch 87/220\n",
      "1352/1352 - 16s - loss: 4.1237e-04 - acc: 0.0266 - val_loss: 5.7481e-04 - val_acc: 0.0267\n",
      "Epoch 88/220\n",
      "1352/1352 - 16s - loss: 4.5490e-04 - acc: 0.0422 - val_loss: 5.4932e-04 - val_acc: 0.0311\n",
      "Epoch 89/220\n",
      "1352/1352 - 16s - loss: 4.4655e-04 - acc: 0.0377 - val_loss: 5.5916e-04 - val_acc: 0.0267\n",
      "Epoch 90/220\n",
      "1352/1352 - 16s - loss: 4.4205e-04 - acc: 0.0385 - val_loss: 5.8870e-04 - val_acc: 0.0111\n",
      "Epoch 91/220\n",
      "1352/1352 - 16s - loss: 4.1409e-04 - acc: 0.0422 - val_loss: 5.2908e-04 - val_acc: 0.0156\n",
      "Epoch 92/220\n",
      "1352/1352 - 16s - loss: 5.0264e-04 - acc: 0.0333 - val_loss: 0.0012 - val_acc: 0.0178\n",
      "Epoch 93/220\n",
      "1352/1352 - 16s - loss: 4.7174e-04 - acc: 0.0281 - val_loss: 5.2749e-04 - val_acc: 0.0178\n",
      "Epoch 94/220\n",
      "1352/1352 - 16s - loss: 4.9676e-04 - acc: 0.0348 - val_loss: 0.0022 - val_acc: 0.0267\n",
      "Epoch 95/220\n",
      "1352/1352 - 16s - loss: 6.8457e-04 - acc: 0.0318 - val_loss: 5.4852e-04 - val_acc: 0.0156\n",
      "Epoch 96/220\n",
      "1352/1352 - 16s - loss: 4.2932e-04 - acc: 0.0325 - val_loss: 6.5150e-04 - val_acc: 0.0489\n",
      "Epoch 97/220\n",
      "1352/1352 - 16s - loss: 4.1010e-04 - acc: 0.0377 - val_loss: 7.1189e-04 - val_acc: 0.0222\n",
      "Epoch 98/220\n",
      "1352/1352 - 16s - loss: 4.2184e-04 - acc: 0.0333 - val_loss: 5.9161e-04 - val_acc: 0.0333\n",
      "Epoch 99/220\n",
      "1352/1352 - 16s - loss: 4.2677e-04 - acc: 0.0333 - val_loss: 8.1199e-04 - val_acc: 0.0289\n",
      "Epoch 100/220\n",
      "1352/1352 - 16s - loss: 4.2031e-04 - acc: 0.0399 - val_loss: 5.2491e-04 - val_acc: 0.0200\n",
      "Epoch 101/220\n",
      "1352/1352 - 16s - loss: 4.3248e-04 - acc: 0.0333 - val_loss: 5.6786e-04 - val_acc: 0.0267\n",
      "Epoch 102/220\n",
      "1352/1352 - 16s - loss: 4.2391e-04 - acc: 0.0362 - val_loss: 5.5251e-04 - val_acc: 0.0178\n",
      "Epoch 103/220\n",
      "1352/1352 - 16s - loss: 4.9642e-04 - acc: 0.0414 - val_loss: 6.2270e-04 - val_acc: 0.0378\n",
      "Epoch 104/220\n",
      "1352/1352 - 16s - loss: 5.1511e-04 - acc: 0.0377 - val_loss: 5.3304e-04 - val_acc: 0.0133\n",
      "Epoch 105/220\n",
      "1352/1352 - 16s - loss: 4.8227e-04 - acc: 0.0414 - val_loss: 5.4294e-04 - val_acc: 0.0289\n",
      "Epoch 106/220\n",
      "1352/1352 - 16s - loss: 4.3197e-04 - acc: 0.0303 - val_loss: 5.4277e-04 - val_acc: 0.0178\n",
      "Epoch 107/220\n",
      "1352/1352 - 16s - loss: 4.4340e-04 - acc: 0.0466 - val_loss: 6.3181e-04 - val_acc: 0.0244\n",
      "Epoch 108/220\n",
      "1352/1352 - 16s - loss: 5.1140e-04 - acc: 0.0348 - val_loss: 5.2642e-04 - val_acc: 0.0267\n",
      "Epoch 109/220\n",
      "1352/1352 - 16s - loss: 4.2000e-04 - acc: 0.0318 - val_loss: 5.2067e-04 - val_acc: 0.0333\n",
      "Epoch 110/220\n",
      "1352/1352 - 16s - loss: 4.2495e-04 - acc: 0.0385 - val_loss: 5.6261e-04 - val_acc: 0.0178\n",
      "Epoch 111/220\n",
      "1352/1352 - 16s - loss: 4.4483e-04 - acc: 0.0355 - val_loss: 5.3366e-04 - val_acc: 0.0400\n",
      "Epoch 112/220\n",
      "1352/1352 - 16s - loss: 4.3196e-04 - acc: 0.0399 - val_loss: 6.4445e-04 - val_acc: 0.0111\n",
      "Epoch 113/220\n",
      "1352/1352 - 16s - loss: 4.5787e-04 - acc: 0.0362 - val_loss: 0.0010 - val_acc: 0.0311\n",
      "Epoch 114/220\n",
      "1352/1352 - 16s - loss: 4.6255e-04 - acc: 0.0385 - val_loss: 6.0858e-04 - val_acc: 0.0378\n",
      "Epoch 115/220\n",
      "1352/1352 - 16s - loss: 4.3432e-04 - acc: 0.0318 - val_loss: 6.2540e-04 - val_acc: 0.0244\n",
      "Epoch 116/220\n",
      "1352/1352 - 16s - loss: 4.7310e-04 - acc: 0.0251 - val_loss: 7.0986e-04 - val_acc: 0.0200\n",
      "Epoch 117/220\n",
      "1352/1352 - 16s - loss: 4.4310e-04 - acc: 0.0311 - val_loss: 6.0849e-04 - val_acc: 0.0156\n",
      "Epoch 118/220\n",
      "1352/1352 - 16s - loss: 4.6062e-04 - acc: 0.0340 - val_loss: 8.9456e-04 - val_acc: 0.0267\n",
      "Epoch 119/220\n",
      "1352/1352 - 16s - loss: 4.4894e-04 - acc: 0.0325 - val_loss: 5.6659e-04 - val_acc: 0.0267\n",
      "Epoch 120/220\n",
      "1352/1352 - 16s - loss: 4.3193e-04 - acc: 0.0303 - val_loss: 8.9736e-04 - val_acc: 0.0244\n",
      "Epoch 121/220\n",
      "1352/1352 - 16s - loss: 5.1772e-04 - acc: 0.0414 - val_loss: 5.2730e-04 - val_acc: 0.0333\n",
      "Epoch 122/220\n",
      "1352/1352 - 16s - loss: 5.2608e-04 - acc: 0.0281 - val_loss: 0.0010 - val_acc: 0.0156\n",
      "Epoch 123/220\n",
      "1352/1352 - 16s - loss: 4.9155e-04 - acc: 0.0385 - val_loss: 7.8496e-04 - val_acc: 0.0244\n",
      "Epoch 124/220\n",
      "1352/1352 - 16s - loss: 4.4592e-04 - acc: 0.0318 - val_loss: 6.6781e-04 - val_acc: 0.0311\n",
      "Epoch 125/220\n",
      "1352/1352 - 16s - loss: 4.3798e-04 - acc: 0.0281 - val_loss: 6.3034e-04 - val_acc: 0.0178\n",
      "Epoch 126/220\n",
      "1352/1352 - 16s - loss: 4.3032e-04 - acc: 0.0436 - val_loss: 6.5669e-04 - val_acc: 0.0489\n",
      "Epoch 127/220\n",
      "1352/1352 - 16s - loss: 4.2643e-04 - acc: 0.0377 - val_loss: 6.2438e-04 - val_acc: 0.0244\n",
      "Epoch 128/220\n",
      "1352/1352 - 16s - loss: 4.0316e-04 - acc: 0.0311 - val_loss: 6.0153e-04 - val_acc: 0.0267\n",
      "Epoch 129/220\n",
      "1352/1352 - 16s - loss: 4.6368e-04 - acc: 0.0333 - val_loss: 5.7945e-04 - val_acc: 0.0311\n",
      "Epoch 130/220\n",
      "1352/1352 - 16s - loss: 4.3776e-04 - acc: 0.0303 - val_loss: 5.1932e-04 - val_acc: 0.0400\n",
      "Epoch 131/220\n",
      "1352/1352 - 16s - loss: 4.4071e-04 - acc: 0.0377 - val_loss: 5.2055e-04 - val_acc: 0.0267\n",
      "Epoch 132/220\n",
      "1352/1352 - 16s - loss: 4.3720e-04 - acc: 0.0370 - val_loss: 6.1121e-04 - val_acc: 0.0133\n",
      "Epoch 133/220\n",
      "1352/1352 - 16s - loss: 4.4055e-04 - acc: 0.0318 - val_loss: 8.1836e-04 - val_acc: 0.0311\n",
      "Epoch 134/220\n",
      "1352/1352 - 16s - loss: 4.1174e-04 - acc: 0.0422 - val_loss: 6.6296e-04 - val_acc: 0.0200\n",
      "Epoch 135/220\n",
      "1352/1352 - 16s - loss: 4.5582e-04 - acc: 0.0377 - val_loss: 5.8942e-04 - val_acc: 0.0133\n",
      "Epoch 136/220\n",
      "1352/1352 - 16s - loss: 4.1603e-04 - acc: 0.0288 - val_loss: 5.4262e-04 - val_acc: 0.0400\n",
      "Epoch 137/220\n",
      "1352/1352 - 16s - loss: 4.3452e-04 - acc: 0.0392 - val_loss: 5.7051e-04 - val_acc: 0.0444\n",
      "Epoch 138/220\n",
      "1352/1352 - 16s - loss: 4.1583e-04 - acc: 0.0444 - val_loss: 5.3699e-04 - val_acc: 0.0400\n",
      "Epoch 139/220\n",
      "1352/1352 - 16s - loss: 4.1202e-04 - acc: 0.0377 - val_loss: 5.3899e-04 - val_acc: 0.0111\n",
      "Epoch 140/220\n",
      "1352/1352 - 16s - loss: 4.7969e-04 - acc: 0.0288 - val_loss: 5.4566e-04 - val_acc: 0.0133\n",
      "Epoch 141/220\n",
      "1352/1352 - 16s - loss: 5.2698e-04 - acc: 0.0237 - val_loss: 5.4686e-04 - val_acc: 0.0289\n",
      "Epoch 142/220\n",
      "1352/1352 - 16s - loss: 4.6282e-04 - acc: 0.0266 - val_loss: 5.4909e-04 - val_acc: 0.0200\n",
      "Epoch 143/220\n",
      "1352/1352 - 16s - loss: 4.5211e-04 - acc: 0.0355 - val_loss: 7.9839e-04 - val_acc: 0.0156\n",
      "Epoch 144/220\n",
      "1352/1352 - 16s - loss: 5.2511e-04 - acc: 0.0362 - val_loss: 0.0010 - val_acc: 0.0289\n",
      "Epoch 145/220\n",
      "1352/1352 - 16s - loss: 4.4653e-04 - acc: 0.0296 - val_loss: 8.8317e-04 - val_acc: 0.0222\n",
      "Epoch 146/220\n",
      "1352/1352 - 16s - loss: 4.5241e-04 - acc: 0.0392 - val_loss: 5.3615e-04 - val_acc: 0.0244\n",
      "Epoch 147/220\n",
      "1352/1352 - 16s - loss: 4.3773e-04 - acc: 0.0414 - val_loss: 8.7335e-04 - val_acc: 0.0200\n",
      "Epoch 148/220\n",
      "1352/1352 - 16s - loss: 4.3545e-04 - acc: 0.0259 - val_loss: 6.2575e-04 - val_acc: 0.0222\n",
      "Epoch 149/220\n",
      "1352/1352 - 16s - loss: 3.9746e-04 - acc: 0.0459 - val_loss: 5.7882e-04 - val_acc: 0.0222\n",
      "Epoch 150/220\n",
      "1352/1352 - 16s - loss: 4.0489e-04 - acc: 0.0399 - val_loss: 7.2672e-04 - val_acc: 0.0222\n",
      "Epoch 151/220\n",
      "1352/1352 - 16s - loss: 4.1444e-04 - acc: 0.0370 - val_loss: 5.3644e-04 - val_acc: 0.0356\n",
      "Epoch 152/220\n",
      "1352/1352 - 16s - loss: 4.3438e-04 - acc: 0.0333 - val_loss: 5.2578e-04 - val_acc: 0.0311\n",
      "Epoch 153/220\n",
      "1352/1352 - 16s - loss: 4.1115e-04 - acc: 0.0266 - val_loss: 5.4670e-04 - val_acc: 0.0222\n",
      "Epoch 154/220\n",
      "1352/1352 - 16s - loss: 3.9128e-04 - acc: 0.0296 - val_loss: 6.1105e-04 - val_acc: 0.0333\n",
      "Epoch 155/220\n",
      "1352/1352 - 16s - loss: 4.0877e-04 - acc: 0.0318 - val_loss: 9.4631e-04 - val_acc: 0.0311\n",
      "Epoch 156/220\n",
      "1352/1352 - 16s - loss: 4.6348e-04 - acc: 0.0377 - val_loss: 5.8749e-04 - val_acc: 0.0156\n",
      "Epoch 157/220\n",
      "1352/1352 - 16s - loss: 3.9547e-04 - acc: 0.0325 - val_loss: 7.0994e-04 - val_acc: 0.0244\n",
      "Epoch 158/220\n",
      "1352/1352 - 16s - loss: 3.9767e-04 - acc: 0.0303 - val_loss: 6.1815e-04 - val_acc: 0.0533\n",
      "Epoch 159/220\n",
      "1352/1352 - 16s - loss: 4.1613e-04 - acc: 0.0311 - val_loss: 5.2259e-04 - val_acc: 0.0156\n",
      "Epoch 160/220\n",
      "1352/1352 - 16s - loss: 4.1421e-04 - acc: 0.0370 - val_loss: 5.3381e-04 - val_acc: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/220\n",
      "1352/1352 - 16s - loss: 3.9362e-04 - acc: 0.0348 - val_loss: 5.2895e-04 - val_acc: 0.0311\n",
      "Epoch 162/220\n",
      "1352/1352 - 16s - loss: 4.0598e-04 - acc: 0.0496 - val_loss: 5.5656e-04 - val_acc: 0.0311\n",
      "Epoch 163/220\n",
      "1352/1352 - 16s - loss: 4.4285e-04 - acc: 0.0370 - val_loss: 5.1261e-04 - val_acc: 0.0289\n",
      "Epoch 164/220\n",
      "1352/1352 - 16s - loss: 4.4876e-04 - acc: 0.0407 - val_loss: 5.3751e-04 - val_acc: 0.0111\n",
      "Epoch 165/220\n",
      "1352/1352 - 16s - loss: 4.3925e-04 - acc: 0.0296 - val_loss: 5.8511e-04 - val_acc: 0.0178\n",
      "Epoch 166/220\n",
      "1352/1352 - 16s - loss: 4.1260e-04 - acc: 0.0348 - val_loss: 5.3581e-04 - val_acc: 0.0200\n",
      "Epoch 167/220\n",
      "1352/1352 - 16s - loss: 4.2702e-04 - acc: 0.0399 - val_loss: 5.3798e-04 - val_acc: 0.0400\n",
      "Epoch 168/220\n",
      "1352/1352 - 16s - loss: 3.8948e-04 - acc: 0.0414 - val_loss: 6.2538e-04 - val_acc: 0.0378\n",
      "Epoch 169/220\n",
      "1352/1352 - 16s - loss: 4.1240e-04 - acc: 0.0311 - val_loss: 5.2820e-04 - val_acc: 0.0244\n",
      "Epoch 170/220\n",
      "1352/1352 - 16s - loss: 4.1694e-04 - acc: 0.0377 - val_loss: 8.2368e-04 - val_acc: 0.0044\n",
      "Epoch 171/220\n",
      "1352/1352 - 16s - loss: 4.2557e-04 - acc: 0.0362 - val_loss: 5.4796e-04 - val_acc: 0.0333\n",
      "Epoch 172/220\n",
      "1352/1352 - 16s - loss: 3.9870e-04 - acc: 0.0325 - val_loss: 6.6405e-04 - val_acc: 0.0244\n",
      "Epoch 173/220\n",
      "1352/1352 - 16s - loss: 4.6963e-04 - acc: 0.0407 - val_loss: 5.9359e-04 - val_acc: 0.0267\n",
      "Epoch 174/220\n",
      "1352/1352 - 16s - loss: 4.1669e-04 - acc: 0.0429 - val_loss: 6.0996e-04 - val_acc: 0.0178\n",
      "Epoch 175/220\n",
      "1352/1352 - 16s - loss: 4.3202e-04 - acc: 0.0377 - val_loss: 6.5789e-04 - val_acc: 0.0267\n",
      "Epoch 176/220\n",
      "1352/1352 - 16s - loss: 4.4814e-04 - acc: 0.0422 - val_loss: 6.0292e-04 - val_acc: 0.0156\n",
      "Epoch 177/220\n",
      "1352/1352 - 16s - loss: 4.0872e-04 - acc: 0.0333 - val_loss: 5.5890e-04 - val_acc: 0.0289\n",
      "Epoch 178/220\n",
      "1352/1352 - 16s - loss: 4.0523e-04 - acc: 0.0340 - val_loss: 5.3079e-04 - val_acc: 0.0178\n",
      "Epoch 179/220\n",
      "1352/1352 - 16s - loss: 4.0871e-04 - acc: 0.0399 - val_loss: 5.2063e-04 - val_acc: 0.0267\n",
      "Epoch 180/220\n",
      "1352/1352 - 16s - loss: 3.9349e-04 - acc: 0.0303 - val_loss: 6.7986e-04 - val_acc: 0.0222\n",
      "Epoch 181/220\n",
      "1352/1352 - 16s - loss: 4.0029e-04 - acc: 0.0192 - val_loss: 6.0937e-04 - val_acc: 0.0222\n",
      "Epoch 182/220\n",
      "1352/1352 - 16s - loss: 4.1868e-04 - acc: 0.0444 - val_loss: 6.5960e-04 - val_acc: 0.0311\n",
      "Epoch 183/220\n",
      "1352/1352 - 16s - loss: 4.7849e-04 - acc: 0.0399 - val_loss: 8.9176e-04 - val_acc: 0.0311\n",
      "Epoch 184/220\n",
      "1352/1352 - 16s - loss: 4.3000e-04 - acc: 0.0592 - val_loss: 7.4639e-04 - val_acc: 0.0267\n",
      "Epoch 185/220\n",
      "1352/1352 - 16s - loss: 4.1372e-04 - acc: 0.0325 - val_loss: 5.9433e-04 - val_acc: 0.0400\n",
      "Epoch 186/220\n",
      "1352/1352 - 16s - loss: 3.8530e-04 - acc: 0.0399 - val_loss: 5.6689e-04 - val_acc: 0.0178\n",
      "Epoch 187/220\n",
      "1352/1352 - 16s - loss: 4.2139e-04 - acc: 0.0451 - val_loss: 6.3334e-04 - val_acc: 0.0200\n",
      "Epoch 188/220\n",
      "1352/1352 - 16s - loss: 4.2775e-04 - acc: 0.0385 - val_loss: 5.9222e-04 - val_acc: 0.0111\n",
      "Epoch 189/220\n",
      "1352/1352 - 16s - loss: 4.2792e-04 - acc: 0.0444 - val_loss: 5.2557e-04 - val_acc: 0.0200\n",
      "Epoch 190/220\n",
      "1352/1352 - 16s - loss: 4.2241e-04 - acc: 0.0399 - val_loss: 7.9098e-04 - val_acc: 0.0244\n",
      "Epoch 191/220\n",
      "1352/1352 - 16s - loss: 4.0479e-04 - acc: 0.0422 - val_loss: 5.3276e-04 - val_acc: 0.0378\n",
      "Epoch 192/220\n",
      "1352/1352 - 16s - loss: 4.1152e-04 - acc: 0.0377 - val_loss: 7.7547e-04 - val_acc: 0.0089\n",
      "Epoch 193/220\n",
      "1352/1352 - 16s - loss: 4.2623e-04 - acc: 0.0385 - val_loss: 0.0011 - val_acc: 0.0311\n",
      "Epoch 194/220\n",
      "1352/1352 - 16s - loss: 5.3393e-04 - acc: 0.0325 - val_loss: 5.4196e-04 - val_acc: 0.0111\n",
      "Epoch 195/220\n",
      "1352/1352 - 16s - loss: 3.9815e-04 - acc: 0.0333 - val_loss: 5.2927e-04 - val_acc: 0.0178\n",
      "Epoch 196/220\n",
      "1352/1352 - 16s - loss: 4.1167e-04 - acc: 0.0348 - val_loss: 6.9158e-04 - val_acc: 0.0200\n",
      "Epoch 197/220\n",
      "1352/1352 - 16s - loss: 3.8859e-04 - acc: 0.0488 - val_loss: 7.2369e-04 - val_acc: 0.0378\n",
      "Epoch 198/220\n",
      "1352/1352 - 16s - loss: 4.2030e-04 - acc: 0.0385 - val_loss: 9.5146e-04 - val_acc: 0.0222\n",
      "Epoch 199/220\n",
      "1352/1352 - 16s - loss: 4.2913e-04 - acc: 0.0473 - val_loss: 5.5073e-04 - val_acc: 0.0689\n",
      "Epoch 200/220\n",
      "1352/1352 - 16s - loss: 3.8784e-04 - acc: 0.0399 - val_loss: 5.4981e-04 - val_acc: 0.0200\n",
      "Epoch 201/220\n",
      "1352/1352 - 16s - loss: 4.0274e-04 - acc: 0.0407 - val_loss: 5.2901e-04 - val_acc: 0.0133\n",
      "Epoch 202/220\n",
      "1352/1352 - 16s - loss: 3.9679e-04 - acc: 0.0259 - val_loss: 5.0705e-04 - val_acc: 0.0311\n",
      "Epoch 203/220\n",
      "1352/1352 - 16s - loss: 4.2976e-04 - acc: 0.0481 - val_loss: 6.2150e-04 - val_acc: 0.0289\n",
      "Epoch 204/220\n",
      "1352/1352 - 16s - loss: 3.9717e-04 - acc: 0.0318 - val_loss: 8.6598e-04 - val_acc: 0.0489\n",
      "Epoch 205/220\n",
      "1352/1352 - 16s - loss: 4.1337e-04 - acc: 0.0377 - val_loss: 7.1641e-04 - val_acc: 0.0267\n",
      "Epoch 206/220\n",
      "1352/1352 - 16s - loss: 4.3020e-04 - acc: 0.0377 - val_loss: 5.2536e-04 - val_acc: 0.0178\n",
      "Epoch 207/220\n",
      "1352/1352 - 16s - loss: 4.0987e-04 - acc: 0.0385 - val_loss: 8.3785e-04 - val_acc: 0.0200\n",
      "Epoch 208/220\n",
      "1352/1352 - 16s - loss: 3.9444e-04 - acc: 0.0392 - val_loss: 5.3443e-04 - val_acc: 0.0222\n",
      "Epoch 209/220\n",
      "1352/1352 - 16s - loss: 3.8420e-04 - acc: 0.0466 - val_loss: 6.1979e-04 - val_acc: 0.0178\n",
      "Epoch 210/220\n",
      "1352/1352 - 16s - loss: 4.8482e-04 - acc: 0.0459 - val_loss: 5.0406e-04 - val_acc: 0.0333\n",
      "Epoch 211/220\n",
      "1352/1352 - 16s - loss: 4.3411e-04 - acc: 0.0362 - val_loss: 5.5375e-04 - val_acc: 0.0244\n",
      "Epoch 212/220\n",
      "1352/1352 - 16s - loss: 4.0004e-04 - acc: 0.0385 - val_loss: 5.6568e-04 - val_acc: 0.0222\n",
      "Epoch 213/220\n",
      "1352/1352 - 16s - loss: 4.0863e-04 - acc: 0.0451 - val_loss: 5.5373e-04 - val_acc: 0.0156\n",
      "Epoch 214/220\n",
      "1352/1352 - 16s - loss: 4.0565e-04 - acc: 0.0414 - val_loss: 5.1657e-04 - val_acc: 0.0178\n",
      "Epoch 215/220\n",
      "1352/1352 - 16s - loss: 3.9898e-04 - acc: 0.0303 - val_loss: 5.2840e-04 - val_acc: 0.0378\n",
      "Epoch 216/220\n",
      "1352/1352 - 16s - loss: 3.9094e-04 - acc: 0.0399 - val_loss: 5.3221e-04 - val_acc: 0.0244\n",
      "Epoch 217/220\n",
      "1352/1352 - 16s - loss: 4.0196e-04 - acc: 0.0333 - val_loss: 6.7590e-04 - val_acc: 0.0444\n",
      "Epoch 218/220\n",
      "1352/1352 - 16s - loss: 4.1512e-04 - acc: 0.0362 - val_loss: 5.3447e-04 - val_acc: 0.0200\n",
      "Epoch 219/220\n",
      "1352/1352 - 16s - loss: 4.5385e-04 - acc: 0.0488 - val_loss: 6.7985e-04 - val_acc: 0.0422\n",
      "Epoch 220/220\n",
      "1352/1352 - 16s - loss: 3.9174e-04 - acc: 0.0348 - val_loss: 5.2140e-04 - val_acc: 0.0222\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train(model, symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fe9854d10f0>, <tensorflow.python.keras.callbacks.History object at 0x7fe98289d518>)\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
